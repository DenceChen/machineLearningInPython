{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "from IPython.display import display, Image\n",
    "from scipy import ndimage\n",
    "from scipy.misc import imresize\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "from six.moves import cPickle as pickle\n",
    "import random\n",
    "# Config the matplotlib backend as plotting inline in IPython\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_size = 500  # Pixel width and height.\n",
    "pixel_depth = 255.0  # Number of levels per pixel.\n",
    "image_size_resized = 160\n",
    "exampleImage = np.ndarray(shape=(image_size,image_size,3),dtype=np.float32)\n",
    "\n",
    "class BatchGenerator(object):\n",
    "    folder = \"\"\n",
    "    globalIndex = 0\n",
    "    def __init__(self, folder):\n",
    "          self.folder = folder\n",
    "    def getCategory(self,imageName):\n",
    "        animal = imageName.split(\".\")[0]\n",
    "        if animal == \"cat\":\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    def nextBatch(self,shuffle=True,batchImageNumber=500):\n",
    "          folder = self.folder\n",
    "          print(\"loading data...\")\n",
    "          \"\"\"Load the data for a single letter label.\"\"\"\n",
    "          image_files = os.listdir(folder)\n",
    "          datasetInput = np.zeros(shape=(batchImageNumber, image_size_resized, image_size_resized,3),\n",
    "                                 dtype=np.float32)\n",
    "          dataSetLabel = np.zeros(shape=(batchImageNumber),\n",
    "                                 dtype=int)\n",
    "          num_images = 0\n",
    "          if shuffle == True:\n",
    "            random.shuffle(image_files)\n",
    "          \n",
    "          trucks = len(image_files)//batchImageNumber\n",
    "          index = self.globalIndex%(trucks-1)\n",
    "          imageCount = 0\n",
    "          for i in range(index*batchImageNumber,(index+1)*batchImageNumber):\n",
    "            image = image_files[i]\n",
    "            image_file = os.path.join(folder, image)\n",
    "            try:\n",
    "              image_data = (ndimage.imread(image_file).astype(float) - \n",
    "                            pixel_depth / 2) / pixel_depth\n",
    "              fullResule_resized = []\n",
    "              if(image_data.shape[0]*image_data.shape[1]>image_size*image_size):\n",
    "                fullResule_resized = imresize(image_data, (image_size_resized,image_size_resized), interp='bilinear', mode=None)\n",
    "              else:\n",
    "                fullResult = np.full(exampleImage.shape,0, dtype=exampleImage.dtype)\n",
    "                #padding image with 0s\n",
    "                fullResult[:image_data.shape[0],:image_data.shape[1],:image_data.shape[2]] = image_data\n",
    "                fullResule_resized = imresize(fullResult, (image_size_resized,image_size_resized), interp='bilinear', mode=None)\n",
    "              datasetInput[imageCount] = fullResule_resized\n",
    "              dataSetLabel[imageCount] = getCategory(image)\n",
    "              #print(dataSetLabel[imageCount])\n",
    "              # show image if want\n",
    "              #plt.imshow(fullResule_resized)\n",
    "            except IOError as e:\n",
    "              print('Could not read:', image_file, ':', e, '- it\\'s ok, skipping.')\n",
    "            imageCount += 1\n",
    "          self.globalIndex += 1\n",
    "          #dataSetLabel = dataSetLabel.reshape(-1)\n",
    "          return datasetInput,dataSetLabel\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n",
      "[1 0 1 0 0 1 1 0 1 1 0 1 1 1 0 0 1 0 0 0 0 1 0 1 0 1 0 1 0 1 1 1 0 0 1 0 0\n",
      " 1 1 0 1 0 1 0 0 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 1\n",
      " 1 1 0 0 0 0 0 1 1 1 1 0 0 1 1 0 1 0 1 1 1 0 1 0 1 0 0 0 1 0 0 1 1 0 1 1 0\n",
      " 1 1 1 0 0 0 1 1 1 0 0 0 1 0 0 1 1 1 1 0 1 0 0 0 1 0 0 0 1 1 1 0 1 0 0 1 0\n",
      " 1 0 1 1 1 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 1 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 0\n",
      " 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0 0\n",
      " 1 0 1 0 1 0 0 0 0 0 1 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 1 1 0\n",
      " 1 1 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 1 1 0 0 0 1 1 0 1 1 1\n",
      " 0 0 0 1 0 1 1 0 1 1 0 0 1 1 1 1 0 0 1 1 1 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0\n",
      " 1 1 0 1 1 1 0 0 1 1 1 0 1 0 1 0 1 1 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 1\n",
      " 1 0 1 1 1 1 0 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 1 0 0 0 1 0 0\n",
      " 1 0 1 1 0 1 0 0 0 0 0 1 1 1 1 0 0 0 1 1 1 1 0 0 1 0 1 0 1 1 0 1 1 0 1 1 1\n",
      " 0 0 0 0 1 1 0 0 1 0 0 0 1 0 1 1 0 1 1 1 1 1 1 0 0 1 0 0 0 1 1 0 1 0 1 1 1\n",
      " 0 1 1 1 0 1 0 1 1 1 0 1 1 0 0 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "dataSetInput,datasetLabel = load_image_from_pickle(\"cat_dog_train\")\n",
    "batchGenerator = BatchGenerator(\"cat_dog_train\")\n",
    "datasetInput,dataSetLabel = batchGenerator.nextBatch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n",
      "0  :batch\n",
      "loading data...\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 10s - loss: 8.4176 - acc: 0.4720    \n",
      "1  :batch\n",
      "loading data...\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 9s - loss: 7.4292 - acc: 0.5340     \n",
      "2  :batch\n",
      "loading data...\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 8s - loss: 7.4929 - acc: 0.5300     \n",
      "3  :batch\n",
      "loading data...\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 9s - loss: 7.7480 - acc: 0.5140     \n",
      "4  :batch\n",
      "loading data...\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 9s - loss: 7.5567 - acc: 0.5260     \n",
      "5  :batch\n",
      "loading data...\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 9s - loss: 7.9393 - acc: 0.5020     \n",
      "6  :batch\n",
      "loading data...\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 9s - loss: 8.3219 - acc: 0.4780     \n",
      "7  :batch\n",
      "loading data...\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 10s - loss: 7.8755 - acc: 0.5060    \n",
      "8  :batch\n",
      "loading data...\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 9s - loss: 8.5770 - acc: 0.4620     \n",
      "9  :batch\n",
      "loading data...\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 13s - loss: 7.6523 - acc: 0.5200    \n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "depth = 16\n",
    "num_hidden = 300\n",
    "num_channels = 3\n",
    "patch_size = 5\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.96,nesterov=True)  \n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(depth, patch_size, patch_size, border_mode='same',subsample=(1,1) ,input_shape=(image_size_resized, image_size_resized, num_channels)))\n",
    "model.add(Activation('relu')) #16x28x28x16\n",
    "model.add(MaxPooling2D(pool_size=(4, 4)))#16x14x14x16\n",
    "model.add(Convolution2D(depth, patch_size, patch_size, border_mode='same'))#16x14x14x16\n",
    "model.add(MaxPooling2D(pool_size=(4, 4)))#16x7x7x16\n",
    "model.add(Flatten())#16x(7x7x16)\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(num_hidden))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "optimizer=\"adam\",metrics=[\"accuracy\"])\n",
    "\n",
    "for i in range(10):\n",
    "    print(i,\" :batch\")\n",
    "    train_dataset, train_labels = batchGenerator.nextBatch()\n",
    "    model.fit(train_dataset, train_labels, nb_epoch=1,verbose=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
